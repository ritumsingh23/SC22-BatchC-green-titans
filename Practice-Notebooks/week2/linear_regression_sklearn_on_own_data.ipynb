{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "K_X2fB9ta-rv"
   },
   "source": [
    "# Linear regression using SKLearn on your own Data!\n",
    "This should look familiar... we now are going to use linear regression on some of our own features. I recommend walking through the code below first, then importing your dataset and working through the same problem with your data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "id": "IecuRdF1a-sG"
   },
   "outputs": [
   ],
   "source": [
    "# import libraries \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "JlrQHpg8a-sI"
   },
   "source": [
    "# Data Loading, Cleaning, and Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "m4-2ySg9W0Fw"
   },
   "source": [
    "Read in your data into a pandas dataframe by replacing the `filename` variable with your file's path. You can also use the current code below to work on a mpg dataset, where the target variable we are predicting is **miles per gallon** based on other car features. \n",
    "\n",
    "> We should choose two columns that we want to run regresssion on. Use the `.head()` function to decide which columns would be best!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "pandas docs - https://pandas.pydata.org/docs/reference/index.html#api <br>\n",
    "seaborn docs - https://seaborn.pydata.org/api.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "id": "mBcweiAXW3bC"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ca6b64c92e9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/mpg.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmy_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#TODO: read in your file by replacing the filename variable with your file's path. You can also use this current code to work on an automobile dataset! filename = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/mpg.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "filename = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/mpg.csv'\n",
    "my_data = pd.read_csv(filename) #TODO: read in your file by replacing the filename variable with your file's path. You can also use this current code to work on an automobile dataset! filename = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/mpg.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "collapsed": false,
    "id": "2n8n7O_8cUxX",
    "outputId": "b1d56a4f-9c74-4cf0-b1eb-055ea2aab14e"
   },
   "outputs": [
   ],
   "source": [
    "my_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "id": "BYHvay0xa-sK"
   },
   "outputs": [
   ],
   "source": [
    "#cleaning the data -- dropping missing and duplicate values for sanity\n",
    "my_data.dropna(inplace = True)\n",
    "my_data.drop_duplicates(inplace = True)\n",
    "my_data = my_data.reset_index(drop=True)\n",
    "\n",
    "length = len(my_data.index) #save length of array of later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "J3L_hb0Ou4sn"
   },
   "source": [
    "Linear regression naturally works best on highly correlated data, so I'm going to create a heatmap to see which variables are correlated! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 344
    },
    "collapsed": false,
    "id": "H7FyJo_QutAX",
    "outputId": "d1ad6159-df64-4882-e2ae-d78cfa814cc5"
   },
   "outputs": [
   ],
   "source": [
    "sns.heatmap(my_data.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "w78dUshNZarz"
   },
   "source": [
    "### Getting to know the problem\n",
    "\n",
    "For my data, my columns inlude `'mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year', 'origin', and 'name'`. \n",
    "\n",
    "To start, I would like to create a linear regression model that uses horsepower (X) to predict miles per gallon (y) and see how strong our linear regression model is. For your data, you should choose two columns as well to represent X and y.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "id": "WW77IzOwZaKp"
   },
   "outputs": [
   ],
   "source": [
    "X = my_data[\"horsepower\"].to_numpy()\n",
    "y = my_data[\"mpg\"].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "cbeaQMpna-sR"
   },
   "source": [
    "# Linear Regression with Scikit-learn's linear regression\n",
    "\n",
    "We can use Scikit-Learnâ€™s Linear Regression to fit the model. Most other models we will use in the course \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "g5Zk8_6ksLur"
   },
   "source": [
    "### Split the data\n",
    "Our model should ignore 20% of data points to use for testing so it doesn't just memorize the data. We need to make sure there are no missing data points before continuing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "np docs - https://numpy.org/doc/stable/reference/index.html#reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "id": "wKS4pvcEsLOF"
   },
   "outputs": [
   ],
   "source": [
    "# Checking for Missing Data\n",
    "if X.shape[0] != y.shape[0]:\n",
    "  print(\"It looks like you have missing data. You may want to preprocess your data more with pandas to delete any rows with missing, NaN, N/A, and null values.\")\n",
    "  \n",
    "idx = np.arange(length) #shuffle our dataset indices so we don't always split the same way!\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "#split our data with 80% for training (learning) and 20% for testing.\n",
    "split_threshold = int(length * 0.8)\n",
    "\n",
    "train_idx = idx[:split_threshold]\n",
    "# Uses the remaining indices for testing\n",
    "test_idx = idx[split_threshold:]\n",
    "\n",
    "# Generates train and test sets and formats them for training.\n",
    "x_train, y_train = X[train_idx], y[train_idx]\n",
    "x_test, y_test = X[test_idx], y[test_idx]\n",
    "x_train= x_train.reshape(-1, 1)\n",
    "y_train= y_train.reshape(-1, 1)\n",
    "x_test = x_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "id": "6IxwdW5osUDI"
   },
   "outputs": [
   ],
   "source": [
    "#let's plot our split data to see how it looks!\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "# plot the train set \n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(x_train,y_train, c='orange')  \n",
    "plt.xlabel('x', fontsize = 20) \n",
    "plt.ylabel('y', fontsize = 20)\n",
    "plt.title('Generated Data - Train')\n",
    "plt.grid('on')\n",
    "\n",
    "# plot the test set \n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(x_test, y_test)  \n",
    "plt.xlabel('x', fontsize = 20) \n",
    "plt.ylabel('y', fontsize = 20)\n",
    "plt.title('Generated Data - Test')\n",
    "plt.grid('on')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "e1m-wKeYsFEl"
   },
   "source": [
    "### Creating and Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "id": "jkPf0bt4a-sV",
    "outputId": "99433807-734f-4a07-fe0a-26b3ad2fb709"
   },
   "outputs": [
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "#Create the model object\n",
    "linr = LinearRegression()\n",
    "#Fit (train) the model -- this is where the ML happens!\n",
    "linr.fit(x_train, y_train)\n",
    "print(linr.intercept_, linr.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "QFb-_EiFrvzQ"
   },
   "source": [
    "### Creating Predictions\n",
    "Predict outputs on our x_test data that we held out. Think of this as a way to see how the model does on new data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "id": "o9ZDJB1qrJ7_"
   },
   "outputs": [
   ],
   "source": [
    "# Predicting using SKLearn\n",
    "y_hat = linr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "collapsed": false,
    "id": "RarVj0Kor54b",
    "outputId": "c3649dc9-e5f0-4930-f4b1-100ad0987777"
   },
   "outputs": [
   ],
   "source": [
    "#plotting results\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(x_test, y_hat, '--')\n",
    "\n",
    "plt.scatter(x_test,y_test, c='orange')  \n",
    "plt.xlabel('x', fontsize = 20) \n",
    "plt.ylabel('y', fontsize = 20)\n",
    "plt.title('Generated Data - Test')\n",
    "plt.grid('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "14TdY4RGr-RG"
   },
   "source": [
    "### Results and Evaluation\n",
    "One way to see if the model is pretty good is the coefficient of determination (R^2) using the `score()` function. You can read about it here: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression.score.\n",
    "\n",
    "Another way is to compare our mean absolute error (MAE). MAE measures the prediction error. Mathematically, it is the average absolute difference between observed and predicted outcomes, MAE = mean(abs(observeds - predicteds)). MAE is less sensitive to outliers compared to RMSE.\n",
    "\n",
    "Read some more about regression model metrics [here](http://www.sthda.com/english/articles/38-regression-model-validation/158-regression-model-accuracy-metrics-r-square-aic-bic-cp-and-more/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "id": "CS2KN6gms_io",
    "outputId": "4f865d48-e1ea-4e80-ebb1-869f5f2052b0"
   },
   "outputs": [
   ],
   "source": [
    "print(linr.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "id": "osxC5vVotKWS",
    "outputId": "aa7e2d67-12af-4389-e7e0-4c23b23e8bf4"
   },
   "outputs": [
   ],
   "source": [
    "MAE = np.mean(abs(y_test - y_hat))\n",
    "MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "2OixzlOot-U6"
   },
   "source": [
    "# Repeat the process!\n",
    "Try running linear regression on multiple combinations of features (columns) on your dataset. What combination yields the best score? How does this connect to your correlation chart? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
   ],
   "name": "linear_regression_sklearn_on_own_data.ipynb",
   "provenance": [
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (Ubuntu Linux)",
   "language": "python",
   "name": "python3-ubuntu",
   "resource_dir": "/usr/local/share/jupyter/kernels/python3-ubuntu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}